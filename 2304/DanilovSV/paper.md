# Разработка алгоритма ранжирования выдачи виртуального помощника из базы знаний

## Аннотация

Использование человеческих ресурсов для технической поддержки сопряжено с тратами на обучение персонала, а также на оплату труда, в связи с чем популярность набирают виртуальные ассистенты. "Искуственный интеллект", максимально релевантно отвечающий на вопросы пользователей.

Данная статья описывает эффективный способ решения проблемы ранжирования выдачи виртуального ассистента, а также содержит в себе описание подхода к разработке приложения виртуальный ассистент (как proof of concept). В результате исследования было разработано приложение, решающее поставленную задачу, обладающее высокой надёжностью и производительностью. 

## Введение
Техническая поддержка является неотъемлимой частью любого современного сервиса. Достаточно часто вопросы пользователей повторяются и ответы на них уже были даны ранее. Процесс обработки вопросов пользователей можно автоматизировать, применив техники машинного обучения. Если такой же (или похожий) вопрос уже был задан и ответ на него есть в базе знаний искуственного интеллекта, можно будет избежать обработки вопроса оператором-человеком, что снизит количество необходимых операторов.

Целью данной работы является увеличение релевантности топ-3 выдачи виртуального помощника из базы знаний. 

Для достижения поставленной цели необходимо выполнить следующие задачи:
* Определить оптимальный алгоритм ранжирования[1] выдачи виртуального ассистента
* Выбрать технологии для хранения данных, кластеризации, а так же для создания интерфейса пользователя  
* Построить датасет
* Выявить признаки в наборе объектов из датасета  
* Разработать proof of concept используемого алгоритма


## Обзор предметной области
### LiveTex
Платформа, позволяющая интегрировать сервис для общения с оператором поддержки на веб-страницу, в Android и iOS приложение. Все операторы являются живыми людьми, что одновременно является и плюсом и минусом: услуги операторов стоят денег, в отличие от бота, однако оператор может предоставить более квалифицированную поддержку.

### Наносемантика
На этой платформе используются боты, а не живые операторы. Боты не обучаются (не применяются технологии машинного обучения), а ведут себя согласно предзаданным шаблонам. Шаблоны позволяют чётко прописывать определённые сценарии (в отличии от машинного обучения, которое в целом представляет скорее неинтерпретируемый "чёрный ящик"), однако обладают рядом минусов, таких как невозможность сохранения контекста диалога и необходимость вручную добавлять новые шаблоны (тогда как используя machine learning этот процесс можно автоматизировать).

### Разработки ЦРТ (центра речевых технологий)
Используется машинное обучение для распознавания речи (voice2text), в остальном сохраняются те же проблемы, что и у LiveTex.


## Критерии сравнения аналогов
### Интеграция с внешними системами
Важным критерием является интеграция платформы поддержки с системами заказчика. Интеграция включает в себя возможность авторизации пользователя-клиента, получение данных из CRM, выгрузку статистики и т.д.

### Простота использования и гибкость конфигурации
Решение должно быть простым в использовании для операторов и администраторов заказчика, а также обладать гибкой конфигурацией (например, выбор алгоритмов переобучение модели и выбор алгоритмов обучения на веб-интерфейсе).

### Поддержка
Важным критерием при выборе используемого инструмента является наличие качественной и подробной документации, а также хорошей поддержки.

## Таблица сравнения по критериям

Аналог\Критерий|Интеграция с внешними системами|Простота и гибкость конфигурации|Поддержка
-|-|-|-
LiveTex|-|-|+
Наносемантика|-|+|+
ЦРТ|-|-|+

## Выводы по итогам сравнения
Ни одна из систем не поддерживает необходимый минимальный уровень интеграции с внешними системами, что можно использовать как одну из killer feature разрабатываемой платформы. Так же killer feature будет являться использование машинного обучения, что сделает диалог клиента с роботом более реалистичным и в следствии клиент с меньшей вероятностью переключится на оператора-человека.

## Выбор метода решения 
На основе сравнения аналогов, а также согласно выявленным требованиям заказчиков, решение должно обладать следующими качествами:
+ Настраиваемость. Настройки системы должны быть вынесены на административный интерфейс таким образом, чтобы для вступления изменений в силу не требовался перезапуск приложения.
+ Простая интеграция с внешними системами. Требуется создать интерфейс для генерации RPC-методов.
+ Кластерность. Система должна поддерживать возможность быть запущенной в кластере, т.е. на нескольких серверах одновременно.
+ Отказоустойчивость. Необходимо обеспечить отказоустойчивость системы, с помощью инструментов мониторинга. Приложениие должно иметь возможность быть восстановленным после ошибки. 
+ Простота развёртывания. Для упрощения развёртывания приложения можно поставлять заказчику docker образ (а также утилиту docker-compose, для создания сети и кластера). 
+ Тестируемость. Приложение должно быть легко тестируемым. 

Для ранжирования понадобятся word embedding алгоритм word2vec, TF-IDF. В качестве метода оптимизации будет использоваться градиентный бустинг, так как он показывает наилучший результат для не очень больших объёмов данных.


## Описание решения

### Технологии
Для кластеризации решения используется СУБД Postgre, поддерживающая master-slave репликацию, а также in memory data grid Hazelcast, дающая возможность использовать распределённые коллекции.  
Для упрощения развёртывания приложения был создан docker образ. Это упрощает и ускоряет перезапуск приложения после критической ошибки, а также позволяет каждому экземпляру приложения иметь одинаковую среду запуска.  
Для разработки основной части приложения используется фреймворк Spring. Для тестирования используются библиотеки Spring Test, Mockito и JUnit. Они позволяют тестировать отдельные компоненты приложения, заменяя другие заглушками. Также, с помощью Spring Test можно проводить интеграционное тестирование всего приложения целиком. Процесс тестирования запускается после каждого push'a в Gitlab-репозиторий с помощью Gitlab CI. Для тестирования был создан специальный docker-контейнер, использование которого позволяет тестировать как отдельные экземпляры приложения, так и кластер из нескольких экземпляров.  

Для реализации алгоритмов машинного обучения были выбраны фреймворки Scikit и Apache Lucene. Scikit является самым популярным инструментов в data science, так как предоставляет удобное API, а также о его использовании написано большое количество материалов. Scikit содержит основные алгоритмы машинного обучения такие как логрегрессия, kNN, random decision tree, gradient descent. Также в нём содержаться методы оценки моделей. Apache Lucene используется для обработки текста: например, для создания индекса из ngram и последующего полнотекстового поиска. Оба фреймворка обладают функционалом online-обучения (т.е. модели можно улучшать на основе новых данных, которые добавляют пользователи приложения).

### Алгоритм
При обучении модели ранкера виртуального ассистента необходимо учесть обязательность предварительных действий с данными, таких как answer merging[2] (например, фразы "Погода в Санкт-Петербурге" и "Погода в СПб" должны обрабатываться как одна и та же фраза), а так же feature merging[3].

Алгоритм ранжирования:  
X — множество объектов  
Xℓ = {x1, . . . , xℓ} — обучающая выборка  
i ≺ j — правильный порядок на парах (i, j) ∈ {1, . . . , ℓ}2  
Задача:  
построить ранжирующую функцию a : X → R такую, что  
i ≺ j ⇒ a(xi) < a(xj)  
Линейная модель ранжирования:  
a(x;w) = x,w  
где xℓ → f1(x), . . . , fn(x) ∈ Rn — вектор признаков объекта x  

D — коллекция текстовых документов (documents)  
Q — множество запросов (queries)  
Dq ⊆ D — множество документов, найденных по запросу q  
X = Q × D — объектами являются пары «запрос, документ»:  
x ≡ (q, d), q ∈ Q, d ∈ Dq  
Y — упорядоченное множество рейтингов  

### Feature Extraction (Выявление признаков)

#### TF-IDF
TF-IDF(q, d) — мера релевантности документа d запросу q  
Мера TF-IDF часто используется для представления документов коллекции в виде числовых векторов, отражающих важность использования каждого слова из некоторого набора слов (количество слов набора определяет размерность вектора) в каждом документе. Подобная модель называется векторной моделью и даёт возможность сравнивать тексты, сравнивая представляющие их вектора в какой-либо метрике (евклидово расстояние, косинусная мера, манхэттенское расстояние, расстояние Чебышёва и др.), то есть производя кластерный анализ. Мера TF-IDF часто используется как один из признаков для ранжирования, т.к. показывает хорошие результаты при кросс-валидации[4].

#### Word2Vec
Векторное представление слов. Представления векторов-слов позволяют вычислять семантическое расстояние между словами. Семаническое расстояние одного документа от другого будет использоваться как один из признаков для ранжирования.

### Оценка модели
Для оценки модели используется заранее подготовленный набор данных. Порядок ответов для данного набора (образец) определён людьми-аннотаторами. Показателем качества модели будет разница между выдачей модели и образцом.

## Выводы

На основании обзора существующих подходов к решению поставленной проблемы и анализа их достоинств и недостатков был разработан и встроен в существующую систему алгоритм ранжирования выдачи виртуального ассистента.

Эффективность работы алгоритма по времени обеспечивается тем, что для получения ответа от обученной модели, необходимо только извлечь признаки из текстового запроса. Такие признаки (например, tf-idf) извлекаются за пренебрежительно малое время.

Разработанное приложение позволяет поддерживать до 1600 одновременных обращений пользователей при использовании кластера из 10 серверов. Дальнейшая работа будет направлена на улучшение показателей качества модели и общей производительности приложения.

## Источники
[1] https://github.com/moevm/scientific_writing-2017/blob/DanilovSV/2304/DanilovSV/paper_base/ranking.pdf 
[2] Gondek D. C. (2012). A framework for merging and ranking of answers in DeepQA. D. C. Gondek, A. Lally, A. Kalyanpur, J. W. Murdock, P. A. Duboue, L. Zhang, Y. Pan, Z. M. Qiu, C. Welty. IBM J. Res. & Dev., vol. 56, no. 3/4, Paper 14.
[3] J. W. Murdock, J. Fan, A. Lally, H. Shima, and B. K. Boguraev, "Textual evidence gathering and analysis," IBM J. Res. & Dev., vol. 56, no. 3/4, Paper 8, pp. 8:1–8:14, May/Jul. 2012.
[4] Yih, W. (2009). Learning term-weighting functions for similarity measures. Wen-tau Yih, D09-1083.
