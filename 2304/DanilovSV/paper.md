# Разработка алгоритма ранжирования выдачи виртуального помощника из базы знаний

## Аннотация

Использование человеческих ресурсов для технической поддержки сопряжено с тратами на обучение персонала, а также на оплату труда, в связи с чем популярность набирают виртуальные ассистенты - искуственный интеллект, релевантно отвечающий на вопросы пользователей.

Данная статья описывает эффективный с точки зрения скорости работы способ решения проблемы ранжирования выдачи виртуального ассистента, а также содержит в себе описание подхода к разработке прототипа приложения виртуальный ассистент. В результате исследования было разработано приложение, решающее поставленную задачу и отвечающее современным запросам надёжности и производительности. 

## Введение
Техническая поддержка является неотъемлимой частью любого современного сервиса. Достаточно часто вопросы пользователей повторяются и ответы на них уже были даны ранее. Процесс обработки вопросов пользователей можно автоматизировать, применив техники машинного обучения. Если такой же или похожий вопрос уже был задан и ответ на него есть в базе знаний искуственного интеллекта, можно будет избежать обработки вопроса оператором-человеком, что снизит количество необходимых операторов.

Целью данной работы является увеличение релевантности порядка выдачи ответов виртуального помощника из базы знаний. 

Для достижения поставленной цели необходимо выполнить следующие задачи:
* Определить обеспечивающий ответ в реальном времени алгоритм ранжирования[1] выдачи виртуального ассистента
* Выбрать технологии для хранения данных, кластеризации, а так же для создания интерфейса пользователя  
* Построить датасет
* Выявить признаки в наборе объектов из датасета  
* Разработать proof of concept используемого алгоритма


## Обзор предметной области
По-скольку алгоритм ранжирования, как правило, является частью системы, оценить и сравнить его с другими алгоритмами не представляется возможным. Поэтому было принято решение сравнивать системы виртуальных ассистентов.

### LiveTex [2]
Платформа, позволяющая интегрировать сервис для общения с оператором поддержки на веб-страницу, в Android и iOS приложение. Все операторы являются живыми людьми, что одновременно является и плюсом и минусом: услуги операторов стоят денег, в отличие от робота, однако оператор может предоставить более квалифицированную поддержку.

### Наносемантика [3]
На этой платформе используются роботы, а не живые операторы. Роботы не обучаются, не применяются технологии машинного обучения, а ведут себя согласно предзаданным шаблонам. Шаблоны позволяют чётко прописывать определённые сценарии, в отличии от машинного обучения, которое в целом представляет скорее неинтерпретируемый "чёрный ящик", однако обладают рядом минусов, таких как невозможность сохранения контекста диалога и необходимость вручную добавлять новые шаблоны, тогда как используя machine learning этот процесс можно автоматизировать.

### Разработки ЦРТ (центра речевых технологий) [4]
Используется машинное обучение для распознавания речи voice2text, в остальном сохраняются те же проблемы, что и у LiveTex.


## Критерии сравнения аналогов
### Интеграция с внешними системами
Важным критерием является интеграция платформы поддержки с системами заказчика. Интеграция включает в себя возможность авторизации пользователя-клиента, получение данных из CRM, выгрузку статистики и т.д.

### Простота использования и гибкость конфигурации
Решение должно быть простым в использовании для операторов и администраторов заказчика, а также обладать гибкой конфигурацией. Например, выбор алгоритмов переобучение модели и выбор алгоритмов обучения на веб-интерфейсе.

### Поддержка
Важным критерием при выборе используемого инструмента является наличие качественной и подробной документации.

В табилце 1 приведено сравнение 

*Таблица 1 "Сравнение по критериям"*  

Аналог\Критерий|Интеграция с внешними системами|Простота и гибкость конфигурации|Поддержка
-|-|-|-
LiveTex|-|-|+
Наносемантика|-|+|+
ЦРТ|-|-|+

## Выводы по итогам сравнения
Ни одна из систем не поддерживает необходимый минимальный уровень интеграции с внешними системами, что можно использовать как одну из основных функциональностей разрабатываемой платформы. Так же важной функцией будет являться использование машинного обучения, что сделает диалог клиента с роботом более реалистичным и в следствии клиент с меньшей вероятностью переключится на оператора-человека.

## Выбор метода решения 
Заказчиками данной системы являются крупный банк, а так же оператор сотовой связи. На основе сравнения аналогов, а также согласно выявленным требованиям заказчиков, решение должно обладать следующими качествами:
+ Настраиваемость. Настройки системы должны быть вынесены на административный интерфейс таким образом, чтобы для вступления изменений в силу не требовался перезапуск приложения.
+ Простая интеграция с внешними системами. Требуется создать интерфейс для генерации RPC-методов.
+ Кластерность. Система должна поддерживать возможность быть запущенной в кластере, т.е. на нескольких серверах одновременно.
+ Отказоустойчивость. Необходимо обеспечить отказоустойчивость системы, с помощью инструментов мониторинга. Приложениие должно иметь возможность быть восстановленным после ошибки. 
+ Простота развёртывания. Для упрощения развёртывания приложения можно поставлять заказчику docker образа, а также утилиту docker-compose, для создания сети и кластера. 
+ Тестируемость. Приложение должно быть легко тестируемым. 

Для ранжирования понадобятся word embedding алгоритм word2vec, TF-IDF. В качестве метода оптимизации будет использоваться градиентный бустинг, так как он показывает наилучший результат для не очень больших объёмов данных[5].


## Описание решения

### Технологии
Для кластеризации решения используется СУБД Postgre, поддерживающая master-slave репликацию, а также in memory data grid Hazelcast, дающая возможность использовать распределённые коллекции.  
Для упрощения развёртывания приложения был создан docker образ. Это упрощает и ускоряет перезапуск приложения после критической ошибки, а также позволяет каждому экземпляру приложения иметь одинаковую среду запуска.  
Для разработки основной части приложения используется фреймворк Spring. Для тестирования используются библиотеки Spring Test, Mockito и JUnit. Они позволяют тестировать отдельные компоненты приложения, заменяя другие заглушками. Также, с помощью Spring Test можно проводить интеграционное тестирование всего приложения целиком. Процесс тестирования запускается после каждого push'a в Gitlab-репозиторий с помощью Gitlab CI. Для тестирования был создан специальный docker-контейнер, использование которого позволяет тестировать как отдельные экземпляры приложения, так и кластер из нескольких экземпляров.  

Для реализации алгоритмов машинного обучения были выбраны фреймворки Scikit и Apache Lucene. Scikit является самым популярным инструментов в data science, так как предоставляет удобное API, а также о его использовании написано большое количество материалов. Scikit содержит основные алгоритмы машинного обучения такие как логрегрессия[6], kNN[7], random decision tree[8], gradient descent[9]. Также в нём содержаться методы оценки моделей. Apache Lucene используется для обработки текста: например, для создания индекса из ngram и последующего полнотекстового поиска. Оба фреймворка обладают функционалом online-обучения, то есть модели можно улучшать на основе новых данных, которые добавляют пользователи приложения.

### Алгоритм
При обучении модели ранжирования для виртуального ассистента необходимо учесть обязательность предварительных действий с данными, таких как answer merging[10]. Например, фразы "Погода в Санкт-Петербурге" и "Погода в СПб" должны обрабатываться как одна и та же фраза, а так же feature merging[11].

Алгоритм ранжирования:  
X — множество объектов  
Xℓ = {x1, . . . , xℓ} — обучающая выборка  
i ≺ j — правильный порядок на парах (i, j) ∈ {1, . . . , ℓ}  
Задача:  
построить ранжирующую функцию a : X → R такую, что  
i ≺ j ⇒ a(xi) < a(xj)  
Линейная модель ранжирования:  
a(x;w) = x,w  
где xℓ → f1(x), . . . , fn(x) ∈ Rn — вектор признаков объекта x  

D — коллекция текстовых документов (documents)  
Q — множество запросов (queries)  
Dq ⊆ D — множество документов, найденных по запросу q  
X = Q × D — объектами являются пары «запрос, документ»:  
x ≡ (q, d), q ∈ Q, d ∈ Dq  
Y — упорядоченное множество рейтингов, y : X → Y — оценки релевантности, поставленные асессорами:
чем выше оценка y(q, d), тем релевантнее документ d запросу q. Правильный порядок определён только между документами,
найденными по одному и тому же запросу q:
(q, d) ≺ (q, d′) ⇔ y(q, d) < y(q, d′).

Основные признаки, используемые в модели:
##### TF-IDF
Мера TF-IDF часто используется для представления документов коллекции в виде числовых векторов, отражающих важность использования каждого слова из некоторого набора слов в каждом документе. Подобная модель называется векторной моделью и даёт возможность сравнивать тексты, сравнивая представляющие их вектора в какой-либо метрике (евклидово расстояние, косинусная мера, манхэттенское расстояние, расстояние Чебышёва и др.). Мера TF-IDF часто используется как один из признаков для ранжирования, т.к. показывает хорошие результаты при кросс-валидации[12].

##### Word2Vec
Векторное представление слов. Представления векторов-слов позволяют вычислять семантическое расстояние между словами. Семаническое расстояние одного документа от другого будет использоваться как один из признаков для ранжирования.

### Оценка модели
Для оценки модели используется заранее подготовленный набор данных, полученный от заказчиков: несколько сотен проаннотированных диалогов реальных пользователей с операторами поддержки. Для обеспечения безопасности, чувствительные пользовательские данные были заранее удалены из диалогов. Порядок ответов для данного набора, образец, определён людьми-аннотаторами. В качестве алгоритма оценки используется N-fold xvalidation, т.е. разбиение датасета на N (в данном случае, N=10) кусков, на N-1 из которых производится обучение, а на оставшемся одном - валидация: цикл повторяется N раз. Показателем качества модели будет разница между выдачей модели и образцом.

## Выводы

На основании обзора существующих подходов к решению поставленной проблемы и анализа их достоинств и недостатков был разработан и встроен в существующую систему алгоритм ранжирования выдачи виртуального ассистента.

Эффективность работы алгоритма по времени обеспечивается тем, что для получения ответа от обученной модели, необходимо только извлечь признаки из текстового запроса. Такие признаки, например, tf-idf, извлекаются за пренебрежительно малое время.

Разработанное приложение позволяет поддерживать до 1600 одновременных обращений пользователей при использовании кластера из 10 серверов. Дальнейшая работа будет направлена на улучшение показателей качества модели и общей производительности приложения.

## Источники
[1] https://github.com/moevm/scientific_writing-2017/blob/DanilovSV/2304/DanilovSV/paper_base/ranking.pdf  
[2] https://livetex.ru/omnikanalnost/  
[3] https://inf.ai/   
[4] https://www.speechpro.ru/product/sistemy-upravleniya-kachestvom-i-avtomatizatsii/chatnavigator   
[5] http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/  
[6] http://www.machinelearning.ru/wiki/index.php?title=Логистическая_регрессия  
[7] http://www.machinelearning.ru/wiki/images/f/fb/Kitov-ML-eng-02-K-NN_optimization.pdf  
[8] https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/
[9] http://mlwiki.org/index.php/Gradient_Descent  
[10] Gondek D. C. (2012). A framework for merging and ranking of answers in DeepQA. D. C. Gondek, A. Lally, A. Kalyanpur, J. W. Murdock, P. A. Duboue, L. Zhang, Y. Pan, Z. M. Qiu, C. Welty. IBM J. Res. & Dev., vol. 56, no. 3/4, Paper 14.   
[11] J. W. Murdock, J. Fan, A. Lally, H. Shima, and B. K. Boguraev, "Textual evidence gathering and analysis," IBM J. Res. & Dev., vol. 56, no. 3/4, Paper 8, pp. 8:1–8:14, May/Jul. 2012.  
[12] Yih, W. (2009). Learning term-weighting functions for similarity measures. Wen-tau Yih, D09-1083.  
